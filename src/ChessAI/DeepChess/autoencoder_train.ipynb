{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "393759d3",
   "metadata": {},
   "source": [
    "# Ref\n",
    "https://github.com/shafitek/DeepChess-AI/blob/master/scripts/DeepChess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e52130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import chess\n",
    "import chess.engine\n",
    "import chess.svg\n",
    "import random\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from models.MiniDeepchess import SiameseNetwork, AutoEncoder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c1c16ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderChessDataset(Dataset):\n",
    "    def __init__(self, whiteWonStates, whiteLostStates):\n",
    "        \"\"\"\n",
    "        Dataset dùng để huấn luyện AutoEncoder từ các trạng thái thắng và thua.\n",
    "\n",
    "        Args:\n",
    "            whiteWonStates (np.ndarray): Trạng thái bàn cờ khi trắng thắng.\n",
    "            whiteLostStates (np.ndarray): Trạng thái bàn cờ khi trắng thua (tức đen thắng).\n",
    "        \"\"\"\n",
    "        sampleSize = min(len(whiteWonStates), len(whiteLostStates))\n",
    "        whiteWonStates = whiteWonStates.copy()\n",
    "        whiteLostStates = whiteLostStates.copy()\n",
    "        np.random.shuffle(whiteWonStates)\n",
    "        np.random.shuffle(whiteLostStates)\n",
    "        whiteWonStates = whiteWonStates[:sampleSize]\n",
    "        whiteLostStates = whiteLostStates[:sampleSize]\n",
    "\n",
    "        # Gán label: trắng thắng → 1, trắng thua (đen thắng) → 0\n",
    "        whiteWonLabels = np.ones((sampleSize, 1))\n",
    "        whiteLostLabels = np.zeros((sampleSize, 1))\n",
    "\n",
    "        self.data = np.concatenate((whiteWonStates, whiteLostStates), axis=0)\n",
    "        self.labels = np.concatenate((whiteWonLabels, whiteLostLabels), axis=0)\n",
    "\n",
    "        # Shuffle cùng lúc data và label\n",
    "        perm = np.random.permutation(len(self.data))\n",
    "        self.data = self.data[perm]\n",
    "        self.labels = self.labels[perm]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Trả về trạng thái bàn cờ và nhãn dưới dạng tensor.\n",
    "\n",
    "        Returns:\n",
    "            x (Tensor): Trạng thái bàn cờ.\n",
    "            y (Tensor): Nhãn (1 nếu trắng thắng, 0 nếu trắng thua).\n",
    "        \"\"\"\n",
    "        x = torch.from_numpy(self.data[index]).float()\n",
    "        y = torch.tensor(self.labels[index]).float().squeeze()  # squeeze để có dạng scalar\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3834e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1600000 white wins, 1600000 black wins\n",
      "Test: 400000 white wins, 400000 black wins\n"
     ]
    }
   ],
   "source": [
    "percentTrain = 0.8\n",
    "\n",
    "whiteWin = np.load(\"./data/whiteWin.npy\")\n",
    "whiteLost = np.load(\"./data/blackWin.npy\")\n",
    "\n",
    "whiteWinTrain = whiteWin[:int(len(whiteWin) * percentTrain)]\n",
    "whiteLostTrain = whiteLost[:int(len(whiteLost) * percentTrain)]\n",
    "whiteWinTest = whiteWin[int(len(whiteWin) * percentTrain):]\n",
    "whiteLostTest = whiteLost[int(len(whiteLost) * percentTrain):]\n",
    "\n",
    "print(f\"Train: {len(whiteWinTrain)} white wins, {len(whiteLostTrain)} black wins\")\n",
    "print(f\"Test: {len(whiteWinTest)} white wins, {len(whiteLostTest)} black wins\")\n",
    "\n",
    "dataset_train = AutoEncoderChessDataset(\n",
    "    whiteWonStates=whiteWinTrain,\n",
    "    whiteLostStates=whiteLostTrain\n",
    ")\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=512, shuffle=True)\n",
    "\n",
    "dataset_test = AutoEncoderChessDataset(\n",
    "    whiteWonStates=whiteWinTest,\n",
    "    whiteLostStates=whiteLostTest\n",
    ")\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05ab5fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AutoEncoder model from checkpoint...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=773, out_features=600, bias=True)\n",
       "    (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Linear(in_features=600, out_features=400, bias=True)\n",
       "    (4): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (7): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.01)\n",
       "    (9): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (10): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=200, bias=True)\n",
       "    (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Linear(in_features=200, out_features=400, bias=True)\n",
       "    (4): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Linear(in_features=400, out_features=600, bias=True)\n",
       "    (7): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.01)\n",
       "    (9): Linear(in_features=600, out_features=773, bias=True)\n",
       "    (10): BatchNorm1d(773, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoEncoder(\n",
    "    layer=[773, 600, 400, 200, 100]\n",
    ")\n",
    "model_path = \"./checkpoints/AutoEncoder.pth\"\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Loading AutoEncoder model from checkpoint...\")\n",
    "    model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b31989",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63863b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x):\n",
    "    return F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "\n",
    "def mse_loss_function(recon_x, x):\n",
    "    return F.mse_loss(recon_x, x, reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8cd7289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, mse_loss_function, device, model_path):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (x, _) in enumerate(tqdm(dataloader)):\n",
    "        x = x.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        recon_batch, _ = model(x)\n",
    "        loss = mse_loss_function(recon_batch, x)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(dataloader)\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, dataloader, mse_loss_function, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for x, _ in dataloader:\n",
    "        x = x.to(device)\n",
    "\n",
    "        recon_batch, _ = model(x)\n",
    "        loss = mse_loss_function(recon_batch, x)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Test Loss: {avg_loss:.6f}\")\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a1c748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 17637/25000 [02:31<00:59, 124.66it/s]"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "patience = 5\n",
    "best_loss = float('inf')\n",
    "patience = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, dataloader_train, optimizer, mse_loss_function, device, model_path)\n",
    "    test_loss = test(model, dataloader_test, mse_loss_function, device)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Test Loss: {test_loss:.6f}\")\n",
    "    \n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(\"✅ Saved best model\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"⏸️ No improvement. Patience counter: {patience_counter}/{patience}\")\n",
    "        if patience_counter >= patience:\n",
    "            print(\"🛑 Early stopping triggered\")\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChessEngine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
